{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a cab rental start-up company. You have successfully run the pilot project and now want to launch your cab service across the country. You have collected the historical data from your pilot project and now have a requirement to apply analytics for fare prediction. You need to design a system that predicts the fare amount for a cab ride in the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import os #getting access to input files\n",
    "import pandas as pd # Importing pandas for performing EDA\n",
    "import numpy as np  # Importing numpy for Linear Algebric operations\n",
    "import matplotlib.pyplot as plt # Importing for Data Visualization\n",
    "import seaborn as sns # Importing for Data Visualization\n",
    "from collections import Counter \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression #ML algorithm\n",
    "from sklearn.model_selection import train_test_split #splitting dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV    \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\edWisor\\Cab Fare Prediction\n"
     ]
    }
   ],
   "source": [
    "#Setting the working directory\n",
    "\n",
    "os.chdir(\"E:/edWisor/Cab Fare Prediction\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data:\n",
    "train  = pd.read_csv(\"train_cab.csv\",na_values={\"pickup_datetime\":\"43\"})\n",
    "test   = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fare_amount          pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0         4.5  2009-06-15 17:26:21 UTC        -73.844311        40.721319   \n",
       "1        16.9  2010-01-05 16:52:16 UTC        -74.016048        40.711303   \n",
       "2         5.7  2011-08-18 00:35:00 UTC        -73.982738        40.761270   \n",
       "3         7.7  2012-04-21 04:30:42 UTC        -73.987130        40.733143   \n",
       "4         5.3  2010-03-09 07:51:00 UTC        -73.968095        40.768008   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.841610         40.712278              1.0  \n",
       "1         -73.979268         40.782004              1.0  \n",
       "2         -73.991242         40.750562              2.0  \n",
       "3         -73.991567         40.758092              1.0  \n",
       "4         -73.956655         40.783762              1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() #checking first five rows of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-27 13:08:24</td>\n",
       "      <td>-73.973320</td>\n",
       "      <td>40.763805</td>\n",
       "      <td>-73.981430</td>\n",
       "      <td>40.743835</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2.323259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-27 13:08:24</td>\n",
       "      <td>-73.986862</td>\n",
       "      <td>40.719383</td>\n",
       "      <td>-73.998886</td>\n",
       "      <td>40.739201</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2.425353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-10-08 11:53:44</td>\n",
       "      <td>-73.982524</td>\n",
       "      <td>40.751260</td>\n",
       "      <td>-73.979654</td>\n",
       "      <td>40.746139</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>0.618628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-12-01 21:12:12</td>\n",
       "      <td>-73.981160</td>\n",
       "      <td>40.767807</td>\n",
       "      <td>-73.990448</td>\n",
       "      <td>40.751635</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1.961033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-12-01 21:12:12</td>\n",
       "      <td>-73.966046</td>\n",
       "      <td>40.789775</td>\n",
       "      <td>-73.988565</td>\n",
       "      <td>40.744427</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>5.387301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0           0  2015-01-27 13:08:24        -73.973320        40.763805   \n",
       "1           1  2015-01-27 13:08:24        -73.986862        40.719383   \n",
       "2           2  2011-10-08 11:53:44        -73.982524        40.751260   \n",
       "3           3  2012-12-01 21:12:12        -73.981160        40.767807   \n",
       "4           4  2012-12-01 21:12:12        -73.966046        40.789775   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  year  Month  Date  \\\n",
       "0         -73.981430         40.743835                1  2015      1    27   \n",
       "1         -73.998886         40.739201                1  2015      1    27   \n",
       "2         -73.979654         40.746139                1  2011     10     8   \n",
       "3         -73.990448         40.751635                1  2012     12     1   \n",
       "4         -73.988565         40.744427                1  2012     12     1   \n",
       "\n",
       "   Day  Hour  Minute  distance  \n",
       "0    1    13       8  2.323259  \n",
       "1    1    13       8  2.425353  \n",
       "2    5    11      53  0.618628  \n",
       "3    5    21      12  1.961033  \n",
       "4    5    21      12  5.387301  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head() #checking first five rows of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data is:  (16067, 7)\n",
      "shape of test data is:  (9914, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of training data is: \",train.shape) #checking the number of rows and columns in training data\n",
    "print(\"shape of test data is: \",test.shape) #checking the number of rows and columns in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount           object\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes #checking the data-types in training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see pickup datetime and fare amount is of object type. So we need to change the data type of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             int64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "year                   int64\n",
       "Month                  int64\n",
       "Date                   int64\n",
       "Day                    int64\n",
       "Hour                   int64\n",
       "Minute                 int64\n",
       "distance             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes #checking the data-types in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>16067.000000</td>\n",
       "      <td>16067.000000</td>\n",
       "      <td>16067.000000</td>\n",
       "      <td>16067.000000</td>\n",
       "      <td>16012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-72.462787</td>\n",
       "      <td>39.914725</td>\n",
       "      <td>-72.462328</td>\n",
       "      <td>39.897906</td>\n",
       "      <td>2.625070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>10.578384</td>\n",
       "      <td>6.826587</td>\n",
       "      <td>10.575062</td>\n",
       "      <td>6.187087</td>\n",
       "      <td>60.844122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-74.438233</td>\n",
       "      <td>-74.006893</td>\n",
       "      <td>-74.429332</td>\n",
       "      <td>-74.006377</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-73.992156</td>\n",
       "      <td>40.734927</td>\n",
       "      <td>-73.991182</td>\n",
       "      <td>40.734651</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-73.981698</td>\n",
       "      <td>40.752603</td>\n",
       "      <td>-73.980172</td>\n",
       "      <td>40.753567</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-73.966838</td>\n",
       "      <td>40.767381</td>\n",
       "      <td>-73.963643</td>\n",
       "      <td>40.768013</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>40.766125</td>\n",
       "      <td>401.083332</td>\n",
       "      <td>40.802437</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>5345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "count      16067.000000     16067.000000       16067.000000      16067.000000   \n",
       "mean         -72.462787        39.914725         -72.462328         39.897906   \n",
       "std           10.578384         6.826587          10.575062          6.187087   \n",
       "min          -74.438233       -74.006893         -74.429332        -74.006377   \n",
       "25%          -73.992156        40.734927         -73.991182         40.734651   \n",
       "50%          -73.981698        40.752603         -73.980172         40.753567   \n",
       "75%          -73.966838        40.767381         -73.963643         40.768013   \n",
       "max           40.766125       401.083332          40.802437         41.366138   \n",
       "\n",
       "       passenger_count  \n",
       "count     16012.000000  \n",
       "mean          2.625070  \n",
       "std          60.844122  \n",
       "min           0.000000  \n",
       "25%           1.000000  \n",
       "50%           1.000000  \n",
       "75%           2.000000  \n",
       "max        5345.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4956.500000</td>\n",
       "      <td>-73.974722</td>\n",
       "      <td>40.751041</td>\n",
       "      <td>-73.973657</td>\n",
       "      <td>40.751743</td>\n",
       "      <td>1.671273</td>\n",
       "      <td>2011.815816</td>\n",
       "      <td>6.857979</td>\n",
       "      <td>16.194170</td>\n",
       "      <td>2.852834</td>\n",
       "      <td>13.467420</td>\n",
       "      <td>29.548416</td>\n",
       "      <td>3.435371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2862.069618</td>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.039072</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>1.278747</td>\n",
       "      <td>1.803347</td>\n",
       "      <td>3.353272</td>\n",
       "      <td>8.838482</td>\n",
       "      <td>1.994451</td>\n",
       "      <td>6.868584</td>\n",
       "      <td>18.674818</td>\n",
       "      <td>3.972374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.252193</td>\n",
       "      <td>40.573143</td>\n",
       "      <td>-74.263242</td>\n",
       "      <td>40.568973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2478.250000</td>\n",
       "      <td>-73.992501</td>\n",
       "      <td>40.736125</td>\n",
       "      <td>-73.991247</td>\n",
       "      <td>40.735254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.298277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4956.500000</td>\n",
       "      <td>-73.982326</td>\n",
       "      <td>40.753051</td>\n",
       "      <td>-73.980015</td>\n",
       "      <td>40.754065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.217412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7434.750000</td>\n",
       "      <td>-73.968013</td>\n",
       "      <td>40.767113</td>\n",
       "      <td>-73.964059</td>\n",
       "      <td>40.768757</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>4.045302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9913.000000</td>\n",
       "      <td>-72.986532</td>\n",
       "      <td>41.709555</td>\n",
       "      <td>-72.990963</td>\n",
       "      <td>41.696683</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>99.996040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count  9914.000000       9914.000000      9914.000000        9914.000000   \n",
       "mean   4956.500000        -73.974722        40.751041         -73.973657   \n",
       "std    2862.069618          0.042774         0.033541           0.039072   \n",
       "min       0.000000        -74.252193        40.573143         -74.263242   \n",
       "25%    2478.250000        -73.992501        40.736125         -73.991247   \n",
       "50%    4956.500000        -73.982326        40.753051         -73.980015   \n",
       "75%    7434.750000        -73.968013        40.767113         -73.964059   \n",
       "max    9913.000000        -72.986532        41.709555         -72.990963   \n",
       "\n",
       "       dropoff_latitude  passenger_count         year        Month  \\\n",
       "count       9914.000000      9914.000000  9914.000000  9914.000000   \n",
       "mean          40.751743         1.671273  2011.815816     6.857979   \n",
       "std            0.035435         1.278747     1.803347     3.353272   \n",
       "min           40.568973         1.000000  2009.000000     1.000000   \n",
       "25%           40.735254         1.000000  2010.000000     4.000000   \n",
       "50%           40.754065         1.000000  2012.000000     7.000000   \n",
       "75%           40.768757         2.000000  2014.000000    10.000000   \n",
       "max           41.696683         6.000000  2015.000000    12.000000   \n",
       "\n",
       "              Date          Day         Hour       Minute     distance  \n",
       "count  9914.000000  9914.000000  9914.000000  9914.000000  9914.000000  \n",
       "mean     16.194170     2.852834    13.467420    29.548416     3.435371  \n",
       "std       8.838482     1.994451     6.868584    18.674818     3.972374  \n",
       "min       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       9.000000     1.000000     8.000000    13.000000     1.298277  \n",
       "50%      16.000000     3.000000    15.000000    33.000000     2.217412  \n",
       "75%      25.000000     5.000000    19.000000    45.000000     4.045302  \n",
       "max      31.000000     6.000000    23.000000    59.000000    99.996040  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Missing Value Analysis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert fare_amount from object to numeric\n",
    "train[\"fare_amount\"] = pd.to_numeric(train[\"fare_amount\"],errors = \"coerce\")  #Using errors=’coerce’. It will replace all non-numeric values with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16067, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16062</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2014-12-12 07:41:00 UTC</td>\n",
       "      <td>-74.008820</td>\n",
       "      <td>40.718757</td>\n",
       "      <td>-73.998865</td>\n",
       "      <td>40.719987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16063</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2009-07-13 07:58:00 UTC</td>\n",
       "      <td>-73.981310</td>\n",
       "      <td>40.781695</td>\n",
       "      <td>-74.014392</td>\n",
       "      <td>40.715527</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16064</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2009-11-11 11:19:07 UTC</td>\n",
       "      <td>-73.972507</td>\n",
       "      <td>40.753417</td>\n",
       "      <td>-73.979577</td>\n",
       "      <td>40.765495</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16065</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2010-05-11 23:53:00 UTC</td>\n",
       "      <td>-73.957027</td>\n",
       "      <td>40.765945</td>\n",
       "      <td>-73.981983</td>\n",
       "      <td>40.779560</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16066</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2011-12-14 06:24:33 UTC</td>\n",
       "      <td>-74.002111</td>\n",
       "      <td>40.729755</td>\n",
       "      <td>-73.983877</td>\n",
       "      <td>40.761975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16066 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0              4.5  2009-06-15 17:26:21 UTC        -73.844311   \n",
       "1             16.9  2010-01-05 16:52:16 UTC        -74.016048   \n",
       "2              5.7  2011-08-18 00:35:00 UTC        -73.982738   \n",
       "3              7.7  2012-04-21 04:30:42 UTC        -73.987130   \n",
       "4              5.3  2010-03-09 07:51:00 UTC        -73.968095   \n",
       "...            ...                      ...               ...   \n",
       "16062          6.5  2014-12-12 07:41:00 UTC        -74.008820   \n",
       "16063         16.1  2009-07-13 07:58:00 UTC        -73.981310   \n",
       "16064          8.5  2009-11-11 11:19:07 UTC        -73.972507   \n",
       "16065          8.1  2010-05-11 23:53:00 UTC        -73.957027   \n",
       "16066          8.5  2011-12-14 06:24:33 UTC        -74.002111   \n",
       "\n",
       "       pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0            40.721319         -73.841610         40.712278              1.0  \n",
       "1            40.711303         -73.979268         40.782004              1.0  \n",
       "2            40.761270         -73.991242         40.750562              2.0  \n",
       "3            40.733143         -73.991567         40.758092              1.0  \n",
       "4            40.768008         -73.956655         40.783762              1.0  \n",
       "...                ...                ...               ...              ...  \n",
       "16062        40.718757         -73.998865         40.719987              1.0  \n",
       "16063        40.781695         -74.014392         40.715527              2.0  \n",
       "16064        40.753417         -73.979577         40.765495              1.0  \n",
       "16065        40.765945         -73.981983         40.779560              1.0  \n",
       "16066        40.729755         -73.983877         40.761975              NaN  \n",
       "\n",
       "[16066 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna(subset= [\"pickup_datetime\"])   #dropping NA values in datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here pickup_datetime variable is in object so we need to change its data type to datetime\n",
    "train['pickup_datetime'] =  pd.to_datetime(train['pickup_datetime'], format='%Y-%m-%d %H:%M:%S UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we will saperate the Pickup_datetime column into separate field like year, month, day of the week, etc\n",
    "\n",
    "train['year'] = train['pickup_datetime'].dt.year\n",
    "train['Month'] = train['pickup_datetime'].dt.month\n",
    "train['Date'] = train['pickup_datetime'].dt.day\n",
    "train['Day'] = train['pickup_datetime'].dt.dayofweek\n",
    "train['Hour'] = train['pickup_datetime'].dt.hour\n",
    "train['Minute'] = train['pickup_datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount                 float64\n",
       "pickup_datetime      datetime64[ns]\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count             float64\n",
       "year                        float64\n",
       "Month                       float64\n",
       "Date                        float64\n",
       "Day                         float64\n",
       "Hour                        float64\n",
       "Minute                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes #Re-checking datatypes after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2015-01-27 13:08:24' does not match format '%Y-%m-%d %H:%M:%S UTC' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, box, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-499dfb01ca52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pickup_datetime\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pickup_datetime\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"%Y-%m-%d %H:%M:%S UTC\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    772\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, box, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, box, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                     result, timezones = array_strptime(\n\u001b[1;32m--> 416\u001b[1;33m                         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m                     )\n\u001b[0;32m    418\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;34m\"%Z\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"%z\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '2015-01-27 13:08:24' does not match format '%Y-%m-%d %H:%M:%S UTC' (match)"
     ]
    }
   ],
   "source": [
    "test[\"pickup_datetime\"] = pd.to_datetime(test[\"pickup_datetime\"],format= \"%Y-%m-%d %H:%M:%S UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we will saperate the Pickup_datetime column into separate field like year, month, day of the week, etc\n",
    "\n",
    "test['year'] = test['pickup_datetime'].dt.year\n",
    "test['Month'] = test['pickup_datetime'].dt.month\n",
    "test['Date'] = test['pickup_datetime'].dt.day\n",
    "test['Day'] = test['pickup_datetime'].dt.dayofweek\n",
    "test['Hour'] = test['pickup_datetime'].dt.hour\n",
    "test['Minute'] = test['pickup_datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes #Re-checking test datatypes after conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations :\n",
    "\n",
    "1. An outlier in pickup_datetime column of value 43\n",
    "2. Passenger count should not exceed 6(even if we consider SUV)\n",
    "3. Latitudes range from -90 to 90. Longitudes range from -180 to 180\n",
    "4. Few missing values and High values of fare and Passenger count are present. So, decided to remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Datetime Variable : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing datetime missing values rows\n",
    "train = train.drop(train[train['pickup_datetime'].isnull()].index, axis=0)\n",
    "print(train.shape)\n",
    "print(train['pickup_datetime'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the passenger count variable : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"passenger_count\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see maximum number of passanger count is 5345 which is actually not possible. So reducing the passenger count to 6 (even if we consider the SUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[train[\"passenger_count\"]> 6 ].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also removing the values with passenger count of 0.\n",
    "train = train.drop(train[train[\"passenger_count\"] == 0 ].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"passenger_count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"passenger_count\"].sort_values(ascending= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing passanger_count missing values rows\n",
    "train = train.drop(train[train['passenger_count'].isnull()].index, axis=0)\n",
    "print(train.shape)\n",
    "print(train['passenger_count'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one passenger count value of 0.12 which is not possible. Hence we will remove fractional passenger value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[train[\"passenger_count\"] == 0.12 ].index, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next checking the Fare Amount variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##finding decending order of fare to get to know whether the outliers are present or not\n",
    "train[\"fare_amount\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(train[\"fare_amount\"]<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[train[\"fare_amount\"]<0].index, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make sure there is no negative values in the fare_amount variable column\n",
    "train[\"fare_amount\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also remove the row where fare amount is zero\n",
    "train = train.drop(train[train[\"fare_amount\"]<1].index, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can see that there is a huge difference in 1st 2nd and 3rd position in decending order of fare amount\n",
    "# so we will remove the rows having fare amounting more that 454 as considering them as outliers\n",
    "\n",
    "train = train.drop(train[train[\"fare_amount\"]> 454 ].index, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminating rows for which value of \"fare_amount\" is missing\n",
    "train = train.drop(train[train['fare_amount'].isnull()].index, axis=0)\n",
    "print(train.shape)\n",
    "print(train['fare_amount'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fare_amount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checking the pickup lattitude and longitude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lattitude----(-90 to 90)\n",
    "#Longitude----(-180 to 180)\n",
    "\n",
    "# we need to drop the rows having  pickup lattitute and longitute out the range mentioned above\n",
    "\n",
    "#train = train.drop(train[train['pickup_latitude']<-90])\n",
    "train[train['pickup_latitude']<-90]\n",
    "train[train['pickup_latitude']>90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence dropping one value of >90\n",
    "train = train.drop((train[train['pickup_latitude']<-90]).index, axis=0)\n",
    "train = train.drop((train[train['pickup_latitude']>90]).index, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['pickup_longitude']<-180]\n",
    "train[train['pickup_longitude']>180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['dropoff_latitude']<-90]\n",
    "train[train['dropoff_latitude']>90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['dropoff_longitude']<-180]\n",
    "train[train['dropoff_longitude']>180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have successfully cleared our both datasets. Thus proceeding for further operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating distance based on the given coordinates :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we know that we have given pickup longitute and latitude values and same for drop. \n",
    "#So we need to calculate the distance Using the haversine formula and we will create a new variable called distance\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(a):\n",
    "    lon1=a[0]\n",
    "    lat1=a[1]\n",
    "    lon2=a[2]\n",
    "    lat2=a[3]\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c =  2 * asin(sqrt(a))\n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km\n",
    "# 1min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'] = train[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']].apply(haversine,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['distance'] = test[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']].apply(haversine,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##finding decending order of fare to get to know whether the outliers are presented or not\n",
    "train['distance'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that top 23 values in the distance variables are very high It means more than 8000 Kms distance they have travelled\n",
    "Also just after 23rd value from the top, the distance goes down to 127, which means these values are showing some outliers\n",
    "We need to remove these values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(train['distance'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(test['distance'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(train['fare_amount'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###we will remove the rows whose distance value is zero\n",
    "\n",
    "train = train.drop(train[train['distance']== 0].index, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will remove the rows whose distance values is very high which is more than 129kms\n",
    "train = train.drop(train[train['distance'] > 130 ].index, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have splitted the pickup date time variable into different varaibles like month, year, day etc so now we dont need to have that pickup_Date variable now. Hence we can drop that, Also we have created distance using pickup and drop longitudes and latitudes so we will also drop pickup and drop longitudes and latitudes variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['pickup_datetime', 'pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude', 'Minute']\n",
    "train = train.drop(drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['passenger_count'] = train['passenger_count'].astype('int64')\n",
    "train['year'] = train['year'].astype('int64')\n",
    "train['Month'] = train['Month'].astype('int64')\n",
    "train['Date'] = train['Date'].astype('int64')\n",
    "train['Day'] = train['Day'].astype('int64')\n",
    "train['Hour'] = train['Hour'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_test = ['pickup_datetime', 'pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude', 'Minute']\n",
    "test = test.drop(drop_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of following:\n",
    "\n",
    "1. Number of Passengers effects the the fare\n",
    "2. Pickup date and time effects the fare\n",
    "3. Day of the week does effects the fare\n",
    "4. Distance effects the fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot on passenger count\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(x=\"passenger_count\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship beetween number of passengers and Fare\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['passenger_count'], y=train['fare_amount'], s=10)\n",
    "plt.xlabel('No. of Passengers')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations :\n",
    "   By seeing the above plots we can easily conclude that:\n",
    "1. single travelling passengers are most frequent travellers.\n",
    "2. At the sametime we can also conclude that highest Fare are coming from single & double travelling passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between date and Fare\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['Date'], y=train['fare_amount'], s=10)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "train.groupby(train[\"Hour\"])['Hour'].count().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowest cabs at 5 AM and highest at and around 7 PM i.e the office rush hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between Time and Fare\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['Hour'], y=train['fare_amount'], s=10)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot We can observe that the cabs taken at 7 am and 23 Pm are the costliest. \n",
    "Hence we can assume that cabs taken early in morning and late at night are costliest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of Day on the number of cab rides\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(x=\"Day\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation :\n",
    "The day of the week does not seem to have much influence on the number of cabs ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationships between day and Fare\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['Day'], y=train['fare_amount'], s=10)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest fares seem to be on a Sunday, Monday and Thursday, and the low on Wednesday and Saturday. May be due to low demand of the cabs on saturdays the cab fare is low and high demand of cabs on sunday and monday shows the high fare prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between distance and fare \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x = train['distance'],y = train['fare_amount'],c = \"g\")\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite obvious that distance will effect the amount of fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality check of training data is uniformly distributed or not-\n",
    "\n",
    "for i in ['fare_amount', 'distance']:\n",
    "    print(i)\n",
    "    sns.distplot(train[i],bins='auto',color='green')\n",
    "    plt.title(\"Distribution for Variable \"+i)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since skewness of target variable is high, apply log transform to reduce the skewness-\n",
    "train['fare_amount'] = np.log1p(train['fare_amount'])\n",
    "\n",
    "#since skewness of distance variable is high, apply log transform to reduce the skewness-\n",
    "train['distance'] = np.log1p(train['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality Re-check to check data is uniformly distributed or not after log transformartion\n",
    "\n",
    "for i in ['fare_amount', 'distance']:\n",
    "    print(i)\n",
    "    sns.distplot(train[i],bins='auto',color='green')\n",
    "    plt.title(\"Distribution for Variable \"+i)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see bell shaped distribution. Hence our continous variables are now normally distributed, we will use not use any  Feature Scalling technique. i.e, Normalization or Standarization for our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality check for test data is uniformly distributed or not-\n",
    "\n",
    "sns.distplot(test['distance'],bins='auto',color='green')\n",
    "plt.title(\"Distribution for Variable \"+i)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since skewness of distance variable is high, apply log transform to reduce the skewness-\n",
    "test['distance'] = np.log1p(test['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechecking the distribution for distance\n",
    "sns.distplot(test['distance'],bins='auto',color='green')\n",
    "plt.title(\"Distribution for Variable \"+i)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see a bell shaped distribution. Hence our continous variables are now normally distributed, we will use not use any  Feature Scalling technique. i.e, Normalization or Standarization for our test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML ALgorithms: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train test split for further modelling\n",
    "X_train, X_test, y_train, y_test = train_test_split( train.iloc[:, train.columns != 'fare_amount'], \n",
    "                         train.iloc[:, 0], test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model on top of training dataset\n",
    "fit_LR = LinearRegression().fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train data\n",
    "pred_train_LR = fit_LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "pred_test_LR = fit_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculating RMSE for test data\n",
    "RMSE_test_LR = np.sqrt(mean_squared_error(y_test, pred_test_LR))\n",
    "\n",
    "##calculating RMSE for train data\n",
    "RMSE_train_LR= np.sqrt(mean_squared_error(y_train, pred_train_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Mean Squared Error For Training data = \"+str(RMSE_train_LR))\n",
    "print(\"Root Mean Squared Error For Test data = \"+str(RMSE_test_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate R^2 for train data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train, pred_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, pred_test_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree Model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_DT = DecisionTreeRegressor(max_depth = 2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train data\n",
    "pred_train_DT = fit_DT.predict(X_train)\n",
    "\n",
    "#prediction on test data\n",
    "pred_test_DT = fit_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculating RMSE for train data\n",
    "RMSE_train_DT = np.sqrt(mean_squared_error(y_train, pred_train_DT))\n",
    "\n",
    "##calculating RMSE for test data\n",
    "RMSE_test_DT = np.sqrt(mean_squared_error(y_test, pred_test_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Mean Squared Error For Training data = \"+str(RMSE_train_DT))\n",
    "print(\"Root Mean Squared Error For Test data = \"+str(RMSE_test_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R^2 calculation for train data\n",
    "r2_score(y_train, pred_train_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R^2 calculation for test data\n",
    "r2_score(y_test, pred_test_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_RF = RandomForestRegressor(n_estimators = 200).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train data\n",
    "pred_train_RF = fit_RF.predict(X_train)\n",
    "#prediction on test data\n",
    "pred_test_RF = fit_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculating RMSE for train data\n",
    "RMSE_train_RF = np.sqrt(mean_squared_error(y_train, pred_train_RF))\n",
    "##calculating RMSE for test data\n",
    "RMSE_test_RF = np.sqrt(mean_squared_error(y_test, pred_test_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Mean Squared Error For Training data = \"+str(RMSE_train_RF))\n",
    "print(\"Root Mean Squared Error For Test data = \"+str(RMSE_test_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate R^2 for train data\n",
    "\n",
    "r2_score(y_train, pred_train_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate R^2 for test data\n",
    "r2_score(y_test, pred_test_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_GB = GradientBoostingRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on train data\n",
    "pred_train_GB = fit_GB.predict(X_train)\n",
    "\n",
    "#prediction on test data\n",
    "pred_test_GB = fit_GB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculating RMSE for train data\n",
    "RMSE_train_GB = np.sqrt(mean_squared_error(y_train, pred_train_GB))\n",
    "##calculating RMSE for test data\n",
    "RMSE_test_GB = np.sqrt(mean_squared_error(y_test, pred_test_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Mean Squared Error For Training data = \"+str(RMSE_train_GB))\n",
    "print(\"Root Mean Squared Error For Test data = \"+str(RMSE_test_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate R^2 for test data\n",
    "r2_score(y_test, pred_test_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate R^2 for train data\n",
    "r2_score(y_train, pred_train_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the results with parameters tuning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Hyperparameter Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Search CV on Random Forest Model\n",
    "\n",
    "RRF = RandomForestRegressor(random_state = 0)\n",
    "n_estimator = list(range(1,20,2))\n",
    "depth = list(range(1,100,2))\n",
    "\n",
    "# Create the random grid\n",
    "rand_grid = {'n_estimators': n_estimator,\n",
    "               'max_depth': depth}\n",
    "\n",
    "randomcv_rf = RandomizedSearchCV(RRF, param_distributions = rand_grid, n_iter = 5, cv = 5, random_state=0)\n",
    "randomcv_rf = randomcv_rf.fit(X_train,y_train)\n",
    "predictions_RRF = randomcv_rf.predict(X_test)\n",
    "\n",
    "view_best_params_RRF = randomcv_rf.best_params_\n",
    "\n",
    "best_model = randomcv_rf.best_estimator_\n",
    "\n",
    "predictions_RRF = best_model.predict(X_test)\n",
    "\n",
    "#R^2\n",
    "RRF_r2 = r2_score(y_test, predictions_RRF)\n",
    "#Calculating RMSE\n",
    "RRF_rmse = np.sqrt(mean_squared_error(y_test,predictions_RRF))\n",
    "\n",
    "print('Random Search CV Random Forest Regressor Model Performance:')\n",
    "print('Best Parameters = ',view_best_params_RRF)\n",
    "print('R-squared = {:0.2}.'.format(RRF_r2))\n",
    "print('RMSE = ',RRF_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(gb.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Search CV on gradient boosting model\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state = 0)\n",
    "n_estimator = list(range(1,20,2))\n",
    "depth = list(range(1,100,2))\n",
    "\n",
    "# Create the random grid\n",
    "rand_grid = {'n_estimators': n_estimator,\n",
    "               'max_depth': depth}\n",
    "\n",
    "randomcv_gb = RandomizedSearchCV(gb, param_distributions = rand_grid, n_iter = 5, cv = 5, random_state=0)\n",
    "randomcv_gb = randomcv_gb.fit(X_train,y_train)\n",
    "predictions_gb = randomcv_gb.predict(X_test)\n",
    "\n",
    "view_best_params_gb = randomcv_gb.best_params_\n",
    "\n",
    "best_model = randomcv_gb.best_estimator_\n",
    "\n",
    "predictions_gb = best_model.predict(X_test)\n",
    "\n",
    "#R^2\n",
    "gb_r2 = r2_score(y_test, predictions_gb)\n",
    "#Calculating RMSE\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test,predictions_gb))\n",
    "\n",
    "print('Random Search CV Gradient Boosting Model Performance:')\n",
    "print('Best Parameters = ',view_best_params_gb)\n",
    "print('R-squared = {:0.2}.'.format(gb_r2))\n",
    "print('RMSE = ', gb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV    \n",
    "## Grid Search CV for random Forest model\n",
    "regr = RandomForestRegressor(random_state = 0)\n",
    "n_estimator = list(range(11,20,1))\n",
    "depth = list(range(5,15,2))\n",
    "\n",
    "# Create the grid\n",
    "grid_search = {'n_estimators': n_estimator,\n",
    "               'max_depth': depth}\n",
    "\n",
    "## Grid Search Cross-Validation with 5 fold CV\n",
    "gridcv_rf = GridSearchCV(regr, param_grid = grid_search, cv = 5)\n",
    "gridcv_rf = gridcv_rf.fit(X_train,y_train)\n",
    "view_best_params_GRF = gridcv_rf.best_params_\n",
    "\n",
    "#Apply model on test data\n",
    "predictions_GRF = gridcv_rf.predict(X_test)\n",
    "\n",
    "#R^2\n",
    "GRF_r2 = r2_score(y_test, predictions_GRF)\n",
    "#Calculating RMSE\n",
    "GRF_rmse = np.sqrt(mean_squared_error(y_test,predictions_GRF))\n",
    "\n",
    "print('Grid Search CV Random Forest Regressor Model Performance:')\n",
    "print('Best Parameters = ',view_best_params_GRF)\n",
    "print('R-squared = {:0.2}.'.format(GRF_r2))\n",
    "print('RMSE = ',(GRF_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search CV for gradinet boosting\n",
    "gb = GradientBoostingRegressor(random_state = 0)\n",
    "n_estimator = list(range(11,20,1))\n",
    "depth = list(range(5,15,2))\n",
    "\n",
    "# Create the grid\n",
    "grid_search = {'n_estimators': n_estimator,\n",
    "               'max_depth': depth}\n",
    "\n",
    "## Grid Search Cross-Validation with 5 fold CV\n",
    "gridcv_gb = GridSearchCV(gb, param_grid = grid_search, cv = 5)\n",
    "gridcv_gb = gridcv_gb.fit(X_train,y_train)\n",
    "view_best_params_Ggb = gridcv_gb.best_params_\n",
    "\n",
    "#Apply model on test data\n",
    "predictions_Ggb = gridcv_gb.predict(X_test)\n",
    "\n",
    "#R^2\n",
    "Ggb_r2 = r2_score(y_test, predictions_Ggb)\n",
    "#Calculating RMSE\n",
    "Ggb_rmse = np.sqrt(mean_squared_error(y_test,predictions_Ggb))\n",
    "\n",
    "print('Grid Search CV Gradient Boosting regression Model Performance:')\n",
    "print('Best Parameters = ',view_best_params_Ggb)\n",
    "print('R-squared = {:0.2}.'.format(Ggb_r2))\n",
    "print('RMSE = ',(Ggb_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of fare from provided test dataset :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already cleaned and processed our test dataset along with our training dataset. Hence we will be predicting using grid search CV for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "## Grid Search CV for random Forest model\n",
    "regr = RandomForestRegressor(random_state = 0)\n",
    "n_estimator = list(range(11,20,1))\n",
    "depth = list(range(5,15,2))\n",
    "\n",
    "# Create the grid\n",
    "grid_search = {'n_estimators': n_estimator,\n",
    "               'max_depth': depth}\n",
    "\n",
    "## Grid Search Cross-Validation with 5 fold CV\n",
    "gridcv_rf = GridSearchCV(regr, param_grid = grid_search, cv = 5)\n",
    "gridcv_rf = gridcv_rf.fit(X_train,y_train)\n",
    "view_best_params_GRF = gridcv_rf.best_params_\n",
    "\n",
    "#Apply model on test data\n",
    "predictions_GRF_test_Df = gridcv_rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_GRF_test_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Predicted_fare'] = predictions_GRF_test_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
